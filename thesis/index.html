<body>
  Hello World!
  <br>
  <h1>Toward generative 3d assets in cross-modality.</h1>
  <br>
  This is the official experimental result of the undergraduate thesis of Qi as a supplementary material.
  <br>
  Feel free to pull request or put comments on this website for any good / constructive suggestions.
  <br>
  Always happy to listen to you and happy to work in this.
  <br>
  Originally, this thesis included some results and summary of the papers fellowing.
  <br>
  And their pipeline of implementation.
  <br>
  > Diffusion Model as good fine-tuning: DreamBooth, ControlNet, (and LoRA).
  <br>
  > Diffusion Model toward highly editive model: Prompt-to-prompt, Null-Text Optimization, Instruct Pix2Pix 
  <br>
  > NeRF as representation for quick and high quality: NeuS, Instant-NGP.
  <br>
  > NeRF toward cross-modality of generation: DreamFusion, DreamBooth3D, RealFusion, Instruct-NeRF2NeRF.
  <br>
</body>
